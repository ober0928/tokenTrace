import requests
import pandas as pd
import time
from datetime import datetime


class CryptoFullHistoryFetcher:
    def __init__(self):
        self.headers = {
            "Accept": "application/json;version=20230203",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        self.base_url = "https://api.geckoterminal.com/api/v2"

    def get_all_ohlcv(self, network, token_ca, timeframe='day', aggregate=1):
        """
        è·å–ä»£å¸ä»ä¸Šçº¿è‡³ä»Šçš„æ‰€æœ‰å†å²æ•°æ®
        timeframe å¯é€‰: 'minute', 'hour', 'day'
        """
        # 1. å…ˆæ‰¾åˆ°ä¸»æ± å­åœ°å€
        pool_address = self._get_best_pool(network, token_ca)
        if not pool_address:
            return None

        all_data = []
        # ä½¿ç”¨å½“å‰æ—¶é—´æˆ³ä½œä¸ºåˆå§‹å›æº¯ç‚¹
        before_timestamp = int(time.time())

        print(f"ğŸš€ å¼€å§‹æŠ“å–å…¨é‡æ•°æ® ({timeframe})...")

        while True:
            url = f"{self.base_url}/networks/{network}/pools/{pool_address}/ohlcv/{timeframe}"
            params = {
                "aggregate": aggregate,
                "before_timestamp": before_timestamp,
                "limit": 1000  # æ¯æ¬¡æ‹‰å–æœ€å¤§å€¼
            }

            try:
                response = requests.get(url, headers=self.headers, params=params)

                # é¢‘ç‡é™åˆ¶å¤„ç† (Rate Limit)
                if response.status_code == 429:
                    print("âš ï¸ è§¦å‘é¢‘ç‡é™åˆ¶ï¼Œå†·å´ 10 ç§’...")
                    time.sleep(10)
                    continue

                if response.status_code != 200:
                    print(f"âŒ æŠ“å–ä¸­æ–­ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    break

                data = response.json().get('data', {}).get('attributes', {}).get('ohlcv_list', [])

                if not data:
                    print("ğŸ å·²åˆ°è¾¾æ•°æ®æºå¤´ï¼ŒæŠ“å–å®Œæˆã€‚")
                    break

                all_data.extend(data)

                # è·å–è¿™æ‰¹æ•°æ®ä¸­æœ€è€çš„ä¸€æ ¹ K çº¿çš„æ—¶é—´æˆ³
                # data æ ¼å¼é€šå¸¸æ˜¯ [timestamp, open, high, low, close, volume]
                oldest_ts = data[-1][0]

                # æ›´æ–° before_timestamp å‡†å¤‡ä¸‹ä¸€æ¬¡å¾ªç¯
                if oldest_ts < before_timestamp:
                    before_timestamp = oldest_ts
                    print(f"ğŸ“… å·²æŠ“å–è‡³: {datetime.fromtimestamp(oldest_ts).strftime('%Y-%m-%d %H:%M')}")
                else:
                    # é¿å…æ­»å¾ªç¯
                    break

                # é€‚å½“å»¶æ—¶ï¼Œä¿æŠ¤ API
                time.sleep(1.5)

            except Exception as e:
                print(f"âŒ è¿è¡Œå¼‚å¸¸: {e}")
                break

        # è½¬æ¢ä¸º DataFrame
        if not all_data:
            return None

        df = pd.DataFrame(all_data, columns=['time', 'open', 'high', 'low', 'close', 'volume'])
        df['time'] = pd.to_datetime(df['time'], unit='s')

        # å»é‡å¹¶æŒ‰æ—¶é—´æ’åº
        df = df.drop_duplicates(subset=['time']).sort_values('time').reset_index(drop=True)
        return df

    def _get_best_pool(self, network, token_address):
        """ç§æœ‰æ–¹æ³•ï¼šæŸ¥æ‰¾æµåŠ¨æ€§æœ€å¤§çš„æ± å­"""
        url = f"{self.base_url}/networks/{network}/tokens/{token_address}/pools"
        res = requests.get(url, headers=self.headers)
        if res.status_code == 200:
            data = res.json().get('data', [])
            if data:
                # æŒ‰æµåŠ¨æ€§æ’åºå–ç¬¬ä¸€
                best_pool = max(data, key=lambda x: float(x['attributes'].get('reserve_in_usd', 0) or 0))
                return best_pool['attributes']['address']
        return None


# --- è¿è¡Œç¤ºä¾‹ ---
if __name__ == "__main__":
    fetcher = CryptoFullHistoryFetcher()

    # ç¤ºä¾‹ï¼šæŠ“å– Solana ä¸Šçš„æŸä¸ªä»£å¸ (ä¾‹å¦‚ JUP)
    # å¦‚æœè¦çœ‹â€œå‘è¡Œè‡³ä»Šâ€ï¼Œå»ºè®® timeframe ç”¨ 'hour' æˆ– 'day'ï¼Œå¦åˆ™æ•°æ®é‡æå¤§
    df_full = fetcher.get_all_ohlcv("solana", "61Wj56QgGyyB966T7YsMzEAKRLcMvJpDbPzjkrCZc4Bi", timeframe='hour')

    if df_full is not None:
        print(f"\nâœ… æŠ“å–æˆåŠŸï¼æ€»è®¡ {len(df_full)} è¡Œæ•°æ®ã€‚")
        print(f"ğŸ“… èµ·å§‹æ—¶é—´: {df_full['time'].min()}")
        print(f"ğŸ“… ç»“æŸæ—¶é—´: {df_full['time'].max()}")
        print(df_full.head())

        # ä¿å­˜åˆ°æœ¬åœ° CSV
        df_full.to_csv("token_full_history.csv", index=False)