import asyncio
import socks
import pandas as pd
from telethon import TelegramClient
from datetime import datetime, timezone

# --- 1. æ ¸å¿ƒé…ç½® ---
API_ID = 2040  # æ›¿æ¢ä¸ºä½ çš„æ•°å­— ID
API_HASH = 'b18441a1ff607e10a989891a5462e627'  # æ›¿æ¢ä¸ºä½ çš„å­—ç¬¦ä¸² Hash
# V2Ray é»˜è®¤ SOCKS5 ç«¯å£é€šå¸¸æ˜¯ 10808
PROXY = (socks.SOCKS5, '127.0.0.1', 7890)

# çˆ¬å–ç›®æ ‡
target_chats = ['@imshards', '@trendisgoodcn']
keywords = ['61Wj56QgGyyB966T7YsMzEAKRLcMvJpDbPzjkrCZc4Bi', 'COPPERINU'] # ä»£å¸åˆçº¦åœ°å€
START_DATE = datetime(2025, 1, 1, tzinfo=timezone.utc)  # å¼€å§‹å›æº¯çš„æ—¥æœŸ


async def scrape_telegram():
    """
    æ¥å…¥ä»£ç†å¹¶å…¨é‡çˆ¬å–å†å²æ¶ˆæ¯
    """
    # æ¥å…¥ proxy å‚æ•°
    client = TelegramClient('session_meme_platform', API_ID, API_HASH, proxy=PROXY)

    async with client:
        print("âœ… ä»£ç†è¿æ¥æˆåŠŸï¼Œæ­£åœ¨ç™»å½•/æ£€æŸ¥ä¼šè¯...")

        all_messages = []

        for chat in TARGET_CHATS:
            print(f"ğŸ” æ­£åœ¨çˆ¬å–ç¾¤ç»„: {chat} ...")

            # ä½¿ç”¨ iter_messages è¿›è¡Œå…¨é‡æœç´¢
            async for message in client.iter_messages(chat, search=KEYWORDS[0]):
                # æ£€æŸ¥æ—¶é—´ï¼Œå¦‚æœæ¶ˆæ¯æ—©äºä»£å¸å‘è¡Œæ—¶é—´åˆ™åœæ­¢
                msg_date = message.date
                if msg_date < START_DATE:
                    break

                if message.text:
                    all_messages.append({
                        'time': msg_date,
                        'text': message.text,
                        'group': chat
                    })

            print(f"ğŸ“Š ä» {chat} ä¸­è·å–äº† {len(all_messages)} æ¡ç›¸å…³è®¨è®º")

        # è½¬æ¢ä¸º DataFrame å¹¶å¤„ç†æ—¶åŒº
        if all_messages:
            df_tg = pd.DataFrame(all_messages)
            # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ (UTC+8) å¹¶ç§»é™¤æ—¶åŒºä¿¡æ¯ä»¥ä¾¿ä¿å­˜ CSV
            df_tg['time'] = df_tg['time'].dt.with_timezone(timezone.utc).dt.tz_convert('Asia/Shanghai').dt.tz_localize(
                None)
            df_tg.to_csv('tg_discussions.csv', index=False)
            print("ğŸ’¾ è®¨è®ºä¿¡æ¯å·²ä¿å­˜è‡³ tg_discussions.csv")
            return df_tg
        else:
            print("âŒ æœªæœç´¢åˆ°ç›¸å…³è®¨è®ºã€‚")
            return None


def merge_with_price():
    """
    å°†çˆ¬åˆ°çš„è®¨è®ºæ•°æ®ä¸ä¹‹å‰æŠ“å–çš„ 15min ä»·æ ¼æ•°æ®å¯¹é½
    """
    try:
        # åŠ è½½æ•°æ®
        df_price = pd.read_csv('token_price_15min.csv', parse_dates=['time'])
        df_tg = pd.read_csv('tg_discussions.csv', parse_dates=['time'])

        # è§„æ•´è®¨è®ºæ—¶é—´åˆ° 15 åˆ†é’Ÿçª—å£
        df_tg['time_bin'] = df_tg['time'].dt.floor('15T')

        # è®¡ç®—çƒ­åº¦ (æ¯ä¸ªçª—å£çš„æ¶ˆæ¯æ•°)
        sentiment_counts = df_tg.groupby('time_bin').size().reset_index(name='mentions')

        # åˆå¹¶
        final_df = pd.merge(df_price, sentiment_counts, left_on='time', right_on='time_bin', how='left')
        final_df['mentions'] = final_df['mentions'].fillna(0)

        final_df.to_csv('final_merged_data.csv', index=False)
        print("ğŸ”¥ æ•°æ®å¯¹é½å®Œæˆï¼å·²ç”Ÿæˆ final_merged_data.csv")

    except FileNotFoundError:
        print("âš ï¸ ç¼ºå°‘å¿…è¦æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ä»·æ ¼æ•°æ®å’Œçˆ¬è™«æ•°æ®éƒ½å·²ç”Ÿæˆã€‚")


async def main():
    # 1. å…ˆæ‰§è¡Œçˆ¬è™«é€»è¾‘
    await scrape_telegram()

    # 2. çˆ¬è™«ç»“æŸåï¼Œæ‰§è¡Œæ•°æ®å¯¹é½é€»è¾‘ï¼ˆå¯¹é½æ˜¯åŒæ­¥æ“ä½œï¼Œç›´æ¥è°ƒå³å¯ï¼‰
    merge_with_price()


if __name__ == '__main__':
    # ä½¿ç”¨ asyncio.run æ›¿ä»£ get_event_loop
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        # æ•è·æ‰‹åŠ¨åœæ­¢ (Ctrl+C)
        pass